{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pybloom import BloomFilter\n",
    "import inspect\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import time\n",
    "%matplotlib notebook\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn import mixture\n",
    "import math\n",
    "\n",
    "def ngram(X, gramsize):\n",
    "    numele = len(X)\n",
    "    minlen = len(X[0])\n",
    "    maxlen = len(X[0])\n",
    "    \n",
    "    for i in X:\n",
    "        templen = len(i)\n",
    "        if(templen>maxlen):\n",
    "            maxlen=templen\n",
    "        if(templen<minlen):\n",
    "            minlen=templen\n",
    "    reqdim = maxlen - gramsize +1\n",
    "    \n",
    "    Y = []\n",
    "    for i in X:\n",
    "        tempy = []\n",
    "        paddedi = i + \"0\"*(maxlen-len(i))\n",
    "        for j in range(0,len(paddedi)-gramsize+1):\n",
    "            tempy.append(paddedi[j:j+gramsize])\n",
    "        if len(tempy) == 0:\n",
    "            tempy = [paddedi]\n",
    "        templeny = len(tempy)\n",
    "        \n",
    "        Y.append(tempy)\n",
    "    return Y\n",
    "\n",
    "def ngramEnforce(X, gramsize, reqdim):\n",
    "    numele = len(X)\n",
    "    minlen = len(X[0])\n",
    "    maxlen = len(X[0])\n",
    "    for i in X:\n",
    "        templen = len(i)\n",
    "        if(templen>maxlen):\n",
    "            maxlen=templen\n",
    "        if(templen<minlen):\n",
    "            minlen=templen\n",
    "    maxlen = reqdim + gramsize -1\n",
    "    Y = []\n",
    "    for i in X:\n",
    "        tempy = []\n",
    "        paddedi = i + \"0\"*(maxlen-len(i))\n",
    "        for j in range(0,len(paddedi)-gramsize+1):\n",
    "            tempy.append(paddedi[j:j+gramsize])\n",
    "        templeny = len(tempy)\n",
    "        \n",
    "        Y.append(tempy)\n",
    "    return np.array(Y)\n",
    "\n",
    "def ngramMaxDimKnown(Xd, gramsize, maxlen):\n",
    "    X = map(str, Xd)\n",
    "    numele = len(X)\n",
    "    reqdim = maxlen - gramsize +1\n",
    "    \n",
    "    Y = []\n",
    "    for i in X:\n",
    "        tempy = []\n",
    "        paddedi = i + \"0\"*(maxlen-len(i))\n",
    "        for j in range(0,len(paddedi)-gramsize+1):\n",
    "            tempy.append(paddedi[j:j+gramsize])\n",
    "        if len(tempy) == 0:\n",
    "            tempy = [paddedi]\n",
    "        templeny = len(tempy)\n",
    "        \n",
    "        Y.append(tempy)\n",
    "    return Y\n",
    "def ngramEnforceMaxKnown(Xd, gramsize, reqdim):\n",
    "    X = map(str, Xd)\n",
    "    numele = len(X)\n",
    "    maxlen = reqdim + gramsize -1\n",
    "    Y = []\n",
    "    for i in X:\n",
    "        tempy = []\n",
    "        paddedi = i + \"0\"*(maxlen-len(i))\n",
    "        for j in range(0,len(paddedi)-gramsize+1):\n",
    "            tempy.append(paddedi[j:j+gramsize])\n",
    "        templeny = len(tempy)\n",
    "        \n",
    "        Y.append(tempy)\n",
    "    return Y\n",
    "\n",
    "def rstripfn(x):\n",
    "    x = x.rstrip('\\n')\n",
    "    \n",
    "    return x.rstrip('\\n')\n",
    "\n",
    "def getDataInString(filename):\n",
    "    with open(filename) as f1:\n",
    "        lst1 = map(rstripfn,f1.readlines())\n",
    "    return lst1\n",
    "\n",
    "def findngram(gramsize, lst1):\n",
    "    lst1g = ngram(lst1, gramsize)\n",
    "\n",
    "    reqdim = len(lst1g[0])\n",
    "    lst1f = []\n",
    "    for i in lst1g:\n",
    "        lst1f.append(map(float, i))\n",
    "\n",
    "    nplst1 = np.array(lst1f)\n",
    "    return (nplst1,reqdim)\n",
    "\n",
    "def preprocess_train(nplst1):\n",
    "    lstf1 = nplst1.astype(float)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    lstS1 = min_max_scaler.fit_transform(lstf1)\n",
    "    return lstS1, min_max_scaler\n",
    "\n",
    "def preprocess_test(nplst1, min_max_scaler):\n",
    "    lstf1 = nplst1.astype(float)\n",
    "    lstS1 = min_max_scaler.transform(lstf1)\n",
    "    return lstS1\n",
    "\n",
    "def trainfn(lstS1, n_compo, maxiter):\n",
    "    clf = mixture.GaussianMixture(n_components=n_compo, covariance_type='full', max_iter=maxiter)\n",
    "    clf.fit(lstS1)\n",
    "    return clf\n",
    "\n",
    "def findmeansigma(clf, lstS1):\n",
    "    meanscore = np.mean(clf.score_samples(lstS1))\n",
    "    meanvar = np.var(clf.score_samples(lstS1))\n",
    "    sigma = math.sqrt(meanvar)\n",
    "    return (meanscore, sigma)\n",
    "\n",
    "def mypred(X, clf, mean, sigma):\n",
    "    scores = clf.score_samples(X)\n",
    "    print(scores)\n",
    "    predictions = []\n",
    "    for i in scores:\n",
    "        print(\"diff is \",abs(i-mean))\n",
    "        if(abs(i-mean)<=max(thres*sigma, 1.0/1e12)):\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(-1)\n",
    "    return predictions\n",
    "def mypredSvm(X, clf):\n",
    "#     scores = clf.predict(X)\n",
    "#     return scores\n",
    "    return np.where(clf.score_samples(X)+clf.intercept_ > -1e-2, 1, -1)\n",
    "\n",
    "def calcncompo(n):\n",
    "    if(n>10000):\n",
    "        return 100\n",
    "    elif(n<60):\n",
    "        return max(1, n/10)\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "def areAllNumeric(l):\n",
    "    l1 = map(isCharacterAscii, l)\n",
    "    return all(l1)\n",
    "\n",
    "def isCharacterAscii(str):\n",
    "    try:\n",
    "        float(str)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def train(filename, sstableID):\n",
    "    lst1 = getDataInString(filename)\n",
    "    if(not areAllNumeric(lst1)):\n",
    "        print(\"returning cause key is not numeric\")\n",
    "        return\n",
    "    if(len(lst1) == 1):\n",
    "        print('returning cause num key is 1')\n",
    "        return\n",
    "    nplst1, reqdim = findngram(gramsize, lst1)\n",
    "    lstS1, min_max_scaler = preprocess_train(nplst1)\n",
    "    n_compo = calcncompo(len(lst1))\n",
    "    clf = trainfn(lstS1, n_compo, maxiter)\n",
    "    mean, sigma = findmeansigma(clf, lstS1)\n",
    "    models[str(sstableID)] = (clf, mean, sigma, reqdim, min_max_scaler)\n",
    "    print('training done with sstableid - ', sstableID)\n",
    "    return\n",
    "\n",
    "def trainIndi(nplst1, sstableID,n_compo):\n",
    "#     lst1 = getDataInString(filename)\n",
    "#     if(not areAllNumeric(lst1)):\n",
    "#         print(\"returning cause key is not numeric\")\n",
    "#         return\n",
    "#     if(len(lst1) == 1):\n",
    "#         print('returning cause num key is 1')\n",
    "#         return\n",
    "#     nplst1, reqdim = findngram(gramsize, lst1)\n",
    "#     print(\"prev mean was \", np.mean(nplst1.transpose()))\n",
    "#     print(\"prev var was \", np.var(nplst1.transpose()))\n",
    "#     lstS1, min_max_scaler = preprocess_train(nplst1)\n",
    "    print(\"passed mean was \",np.mean(nplst1.transpose()))\n",
    "    print(\"passed sigma was \",np.var(nplst1.transpose()))\n",
    "#     n_compo = calcncompo(len(lst1))\n",
    "    clf = trainfn(nplst1, n_compo, maxiter)\n",
    "    print(\"found means \")\n",
    "    print(np.sort(clf.means_.transpose()[0]))\n",
    "    print(\"cov matrix \")\n",
    "    print(clf.covariances_)\n",
    "    print(\"weights :\")\n",
    "    print(clf.weights_)\n",
    "    mean, sigma = findmeansigma(clf, nplst1)\n",
    "    print(\"mean is \",str(mean))\n",
    "    print(\"sigma is \", str(sigma))\n",
    "    reqdim = len(nplst1[0])\n",
    "    models[str(sstableID)] = (clf, mean, sigma, reqdim)\n",
    "    print('training done with sstableid - ', sstableID)\n",
    "    return\n",
    "\n",
    "def trainIndiSvm(nplst1, sstableID, nu, gamma, models):\n",
    "    print(\"passed mean was \",np.mean(nplst1, axis=0))\n",
    "    print(\"passed sigma was \",np.var(nplst1, axis=0))\n",
    "    clf = svm.OneClassSVM(nu=nu, kernel=\"rbf\", gamma=gamma)\n",
    "    clf.fit(nplst1)\n",
    "    reqdim = len(nplst1[0])\n",
    "#     print(\"reqdim is \",reqdim)\n",
    "    models[str(sstableID)] = (clf, reqdim)\n",
    "    print('training done with sstableid - ', sstableID)\n",
    "    return models\n",
    "def test(keyPredstr, sstableID):\n",
    "    if(keyPredstr == ''):\n",
    "        print('returning cause string is empty')\n",
    "        return 0\n",
    "    if(not isCharacterAscii(keyPredstr)):\n",
    "        print('returning cause not numric')\n",
    "        return 0\n",
    "    keyPred = [str(keyPredstr)]\n",
    "    if sstableID in models:\n",
    "        # sizeofmodels()\n",
    "        clf, mean, sigma, reqdim, min_max_scaler = models[str(sstableID)]\n",
    "        keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "        keyPredS = preprocess_test(keyPredg, min_max_scaler)\n",
    "        prediction = mypred(keyPredS, clf, mean, sigma)\n",
    "        return prediction[0]\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def testIndi(keyPredg, sstableID):\n",
    "#     if(keyPredstr == ''):\n",
    "#         print('returning cause string is empty')\n",
    "#         return 0\n",
    "#     if(not isCharacterAscii(keyPredstr)):\n",
    "#         print('returning cause not numric')\n",
    "#         return 0\n",
    "#     keyPred = [str(keyPredstr)]\n",
    "    if str(sstableID) in models:\n",
    "        # sizeofmodels()\n",
    "        clf, mean, sigma, reqdim= models[str(sstableID)]\n",
    "#         keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "#         keyPredS = preprocess_test([keyPredg], min_max_scaler)\n",
    "        prediction = mypred([keyPredg], clf, mean, sigma)\n",
    "        return prediction[0]\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "def testIndiSvm(keyPredg, sstableID, models):\n",
    "#     if(keyPredstr == ''):\n",
    "#         print('returning cause string is empty')\n",
    "#         return 0\n",
    "#     if(not isCharacterAscii(keyPredstr)):\n",
    "#         print('returning cause not numric')\n",
    "#         return 0\n",
    "#     keyPred = [str(keyPredstr)]\n",
    "    if str(sstableID) in models:\n",
    "        # sizeofmodels()\n",
    "        clf, reqdim= models[str(sstableID)]\n",
    "#         keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "#         keyPredS = preprocess_test([keyPredg], min_max_scaler)\n",
    "        prediction = mypredSvm([keyPredg], clf)\n",
    "        return prediction[0]\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "\n",
    "def testIndi2(keyPredg, sstableID):\n",
    "#     if(keyPredstr == ''):\n",
    "#         print('returning cause string is empty')\n",
    "#         return 0\n",
    "#     if(not isCharacterAscii(keyPredstr)):\n",
    "#         print('returning cause not numric')\n",
    "#         return 0\n",
    "#     keyPred = [str(keyPredstr)]\n",
    "    if str(sstableID) in models:\n",
    "        # sizeofmodels()\n",
    "        clf, mean, sigma, reqdim= models[str(sstableID)]\n",
    "#         keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "#         keyPredS = preprocess_test([keyPredg], min_max_scaler)\n",
    "        prediction = mypred(keyPredg, clf, mean, sigma)\n",
    "        return prediction\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "def testIndiSvm2(keyPredg, sstableID, models):\n",
    "#     if(keyPredstr == ''):\n",
    "#         print('returning cause string is empty')\n",
    "#         return 0\n",
    "#     if(not isCharacterAscii(keyPredstr)):\n",
    "#         print('returning cause not numric')\n",
    "#         return 0\n",
    "#     keyPred = [str(keyPredstr)]\n",
    "    if str(sstableID) in models:\n",
    "        # sizeofmodels()\n",
    "        clf, reqdim= models[str(sstableID)]\n",
    "#         keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "#         keyPredS = preprocess_test([keyPredg], min_max_scaler)\n",
    "        prediction = mypredSvm(keyPredg, clf)\n",
    "        return prediction\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "def sizeofmodels():\n",
    "    l = []\n",
    "    for sstableID in models:\n",
    "        clf, mean, sigma, reqdim, min_max_scaler = models[str(sstableID)]\n",
    "        print(\"yo\")\n",
    "        print(clf)\n",
    "        p = pickle.dumps(clf)\n",
    "        tempsize = sys.getsizeof(p)\n",
    "        # print(str(tempsize))\n",
    "        # print(sys.getsizeof(p))\n",
    "        print(sstableID, sys.getsizeof(p))\n",
    "def sumsizeofmodels(models):\n",
    "    agg =0\n",
    "    for sstableID in models:\n",
    "        clf, mean, sigma, reqdim= models[str(sstableID)]\n",
    "        print(\"yo\")\n",
    "        print(clf)\n",
    "        p = pickle.dumps(clf)\n",
    "        tempsize = sys.getsizeof(p)\n",
    "        agg += tempsize\n",
    "        # print(str(tempsize))\n",
    "        # print(sys.getsizeof(p))\n",
    "        print(sstableID, sys.getsizeof(p))\n",
    "    return agg\n",
    "def sumsizeofmodelssvm(models):\n",
    "    agg =0\n",
    "    for sstableID in models:\n",
    "        clf, reqdim= models[str(sstableID)]\n",
    "        print(\"yo\")\n",
    "        print(clf)\n",
    "        p = pickle.dumps(clf)\n",
    "        tempsize = sys.getsizeof(p)\n",
    "        agg += tempsize\n",
    "        # print(str(tempsize))\n",
    "        # print(sys.getsizeof(p))\n",
    "        print(sstableID, sys.getsizeof(p))\n",
    "    return agg\n",
    "def sumsizeofbloom(bloomfilters):\n",
    "    agg =0\n",
    "    for f in bloomfilters.values():\n",
    "        agg += f.num_bits\n",
    "    agg = agg/8\n",
    "    return agg\n",
    "\n",
    "def readFileByLines(filename):\n",
    "    f = open(filename, 'r')\n",
    "    lst = f.readlines()\n",
    "    f.close()\n",
    "#     print(lst)\n",
    "#     lst = map(str.rstrip, lst)\n",
    "    return lst\n",
    "def parseVdisk(lst):\n",
    "    lst = [s.split(':') for s in lst]\n",
    "#     vid = []\n",
    "#     blc = [] \n",
    "    mat = []\n",
    "    for ele in lst:\n",
    "#         vid.append(int(ele[1]))\n",
    "#         blc.append(int(ele[2], 16))\n",
    "        mat.append([float(int(ele[1]))/1e0,float(int(ele[2], 16))/1e0])\n",
    "#     print(vid, blc)\n",
    "#     return (vid, blc)\n",
    "    return mat\n",
    "def createNgramsPerSStable(thisssTableData, alltemptableData):\n",
    "    mingram = 4\n",
    "    maxgram = 4\n",
    "    initialDimension = alltemptableData.shape[1]\n",
    "    \n",
    "    extrapolatedData = thisssTableData\n",
    "    findimlist = []\n",
    "    for realFeature in range(initialDimension):\n",
    "    #     not taking care of negative features\n",
    "        thisFeatureData = thisssTableData[:,realFeature]\n",
    "        maxlen = len(str(np.max(alltemptableData[:,realFeature])))\n",
    "        dimlist = []\n",
    "        for gramsize in range(mingram, min(maxgram,maxlen)+1):\n",
    "#             print(thisFeatureData[0], gramsize, maxlen)\n",
    "#             print(gramsize)\n",
    "            thisFeatureDataOfGramSize = np.array(ngramMaxDimKnown(thisFeatureData, gramsize, maxlen),dtype=np.float)\n",
    "#             print(thisFeatureDataOfGramSize[0])\n",
    "#             print(thisFeatureDataOfGramSize.shape)\n",
    "            reqdimForLater = thisFeatureDataOfGramSize.shape[1]\n",
    "#             print(reqdimForLater)\n",
    "            dimlist.append(reqdimForLater)\n",
    "            extrapolatedData = np.append(extrapolatedData, thisFeatureDataOfGramSize, axis=1)\n",
    "        findimlist += dimlist\n",
    "    return (extrapolatedData, findimlist)\n",
    "def createNgrams(ssTableData, alltemptableData):\n",
    "    ngramData = {}\n",
    "    dimlists = []\n",
    "    for i in range(len(ssTableData)):\n",
    "        (bigData, dimlist)=createNgramsPerSStable(ssTableData[i], alltemptableData)\n",
    "        ngramData[i] = bigData\n",
    "        dimlists.append(dimlist)\n",
    "    return (ngramData, dimlists)\n",
    "# def createNgramsPerSStableEnforce(thisssTableData, alltemptableData, dimlist):\n",
    "#     mingram = 3\n",
    "#     maxgram = 7\n",
    "#     initialDimension = alltemptableData.shape[1]\n",
    "    \n",
    "#     extrapolatedData = thisssTableData\n",
    "#     findimlist = []\n",
    "#     for realFeature in range(initialDimension):\n",
    "#     #     not taking care of negative features\n",
    "#         thisFeatureData = thisssTableData[:,realFeature]\n",
    "#         maxlen = len(str(np.max(alltemptableData[:,realFeature])))\n",
    "#         dimlist = []\n",
    "#         for gramsize in range(mingram, min(maxgram,maxlen)+1):\n",
    "# #             print(thisFeatureData[0], gramsize, maxlen)\n",
    "# #             print(gramsize)\n",
    "#             thisFeatureDataOfGramSize = np.array(ngramMaxDimKnown(thisFeatureData, gramsize, maxlen),dtype=np.float)\n",
    "# #             print(thisFeatureDataOfGramSize[0])\n",
    "# #             print(thisFeatureDataOfGramSize.shape)\n",
    "#             reqdimForLater = thisFeatureDataOfGramSize.shape[1]\n",
    "# #             print(reqdimForLater)\n",
    "#             dimlist.append(reqdimForLater)\n",
    "#             extrapolatedData = np.append(extrapolatedData, thisFeatureDataOfGramSize, axis=1)\n",
    "#         findimlist += dimlist\n",
    "#     return (extrapolatedData, findimlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gramtuple = createNgramsPerSStable(ssTableData[0], alltemptableData)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gramtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lolarr = createNgrams(ssTableData[0], alltemptableData)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lolarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alltemptableData[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(alltemptableData[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    foldername = \"metadata_maps/vdisk/*.db\"\n",
    "    files = sorted(glob.glob(foldername))\n",
    "    ctr=0\n",
    "    alltemptableData = []\n",
    "    for fle in files:\n",
    "        thisline = readFileByLines(fle)\n",
    "    #     if(len(thisline)>1000):\n",
    "    #         continue\n",
    "        mat = parseVdisk(thisline)\n",
    "        ssTableData[ctr] = np.array(mat).reshape(-1,2)\n",
    "        ctr+=1\n",
    "        alltemptableData+=mat\n",
    "        print(ctr,len(thisline))\n",
    "    # print(lines)\n",
    "    alltemptableData = np.array(alltemptableData).reshape(-1,2)\n",
    "    return (ssTableData, alltemptableData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScalers():\n",
    "    scalers = {}\n",
    "    for i in range(0,len(ssTableData)):\n",
    "        thistableData = ssTableData[i]\n",
    "        scaler = preprocessing.StandardScaler().fit(thistableData)\n",
    "        scalers[i] = scaler\n",
    "    return scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "# alltemptableData = generateGaussArrTwoDim(\n",
    "#     numclustersPerSStable*numSstable, gapBetweenClusters, clusterSigma, numelePerCluster )\n",
    "# np.random.shuffle(alltemptableData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(ssTableData)):\n",
    "#     thistableData = alltemptableData[i*numclustersPerSStable:(i+1)*numclustersPerSStable]\n",
    "#     ssTableData[i] = thistableData.reshape(-1,thistableData.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# thistableData = ssTableData[0]\n",
    "# trainIndiSvm(scalers[0].transform(thistableData),0, nu, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "def trainFn(nu, gamma):\n",
    "    # train the model on generated data\n",
    "    models = {}\n",
    "    for i in range(0,len(ssTableData)):\n",
    "        starttime = time.time()\n",
    "        thistableData = ssTableData[i]\n",
    "        models = trainIndiSvm(scalers[i].transform(thistableData),i, nu, gamma, models)\n",
    "        endtime = time.time()\n",
    "        print(str(nu),str(gamma),\"time taken \", (endtime-starttime))\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pklfile = open(\"svmmodelstandardscaled_0.1_50\", \"rb\")\n",
    "# models = pkl.load(pklfile)\n",
    "# pklfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# put into bloom filter false negatives\n",
    "def putIntoBloomFilters(models):\n",
    "    bloomfilters = {}\n",
    "    errorsTrain = {}\n",
    "    for i in range(0,len(ssTableData)):\n",
    "        print(\"bf creating for \",i)\n",
    "        thistableData = ssTableData[i]\n",
    "        thistableDataTranspose0 = thistableData.transpose()[0]\n",
    "        if removeClassifier:\n",
    "            newCapacity = max(len(thistableData),1)\n",
    "            print(\"newCapacity \",newCapacity)\n",
    "            f = BloomFilter(capacity=newCapacity, error_rate=errorRate)\n",
    "            for j in range(0,len(thistableData)):\n",
    "                f.add(separator.join(map(str,thistableData[j])))\n",
    "            bloomfilters[i] = f\n",
    "        else:\n",
    "            falseNegativeAns = testIndiSvm2(scalers[i].transform(thistableData), i, models)\n",
    "        #     print(falseNegativeAns)\n",
    "            numFalseNeg = falseNegativeAns.tolist().count(-1)\n",
    "        #     newCapacity = int(capacityBloom*1.0*numFalseNeg/len(thistableData))\n",
    "            newCapacity = max(numFalseNeg,1)\n",
    "            print(\"newCapacity \",newCapacity)\n",
    "            f = BloomFilter(capacity=newCapacity, error_rate=errorRate)\n",
    "            for j in range(0,len(thistableData)):\n",
    "                if(falseNegativeAns[j]==-1 or removeClassifier):\n",
    "        #             print(\"adding \", thistableDataTranspose0[j])\n",
    "                    f.add(separator.join(map(str,thistableData[j])))\n",
    "            bloomfilters[i] = f\n",
    "        errorsTrain[i] = newCapacity\n",
    "    return (bloomfilters,errorsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "def performTests(models, bloomfilters):\n",
    "    # create test data\n",
    "    # For now test data is all data\n",
    "    # calculate false positives for test data\n",
    "    truePositive_c=0\n",
    "    truePositive_bf=0\n",
    "    truePositive=0\n",
    "    falsePositive_c=0\n",
    "    falsePositive_bf=0\n",
    "    falsePositive=0\n",
    "    trueNegative=0\n",
    "    for i in range(0, len(ssTableData)):\n",
    "        print(\"on sstable number \", i)\n",
    "        thistableData = ssTableData[i]\n",
    "        thistableDataTranspose0 = thistableData.transpose()[0]\n",
    "        for elemind in range(0,len(thistableData),skipFactor):\n",
    "            elem = thistableData[elemind]\n",
    "            for j in range(0,len(ssTableData)):\n",
    "                if removeClassifier:\n",
    "                    cAnswer = False\n",
    "                else:\n",
    "                    cAnswer = (testIndiSvm(scalers[j].transform([elem])[0],j, models)==1)\n",
    "    #             print(cAnswer)\n",
    "                if not cAnswer:\n",
    "                    bfAnswer = separator.join(map(str,elem)) in bloomfilters[j]\n",
    "                    finAnswer = bfAnswer\n",
    "                else:\n",
    "                    bfAnswer = None\n",
    "                    finAnswer = cAnswer\n",
    "                if finAnswer:\n",
    "                    if(i==j):\n",
    "                        #True answer true positive\n",
    "                        #break because you found answer\n",
    "                        truePositive+=1\n",
    "                        if bfAnswer is None:\n",
    "                            truePositive_c+=1\n",
    "                        else:\n",
    "                            truePositive_bf+=1\n",
    "                        break\n",
    "                    else:\n",
    "                        #False answer false positive\n",
    "                        falsePositive+=1\n",
    "                        if bfAnswer is None:\n",
    "                            falsePositive_c+=1\n",
    "                        else:\n",
    "                            falsePositive_bf+=1\n",
    "                else:\n",
    "                    if(i==j):\n",
    "                        raise ValueEroor(\"not possible\")\n",
    "                    else:\n",
    "                        #True answer true negative\n",
    "                        trueNegative+=1\n",
    "    fprate = falsePositive*1.0/(falsePositive+trueNegative)\n",
    "    return (fprate,\n",
    "            truePositive_c,truePositive_bf,truePositive,\n",
    "            falsePositive_c,falsePositive_bf,falsePositive,\n",
    "            trueNegative)\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistModel(models, nu, gamma):\n",
    "    pickle_out = open(\"svmModels/svmmodelstandardscaled_\"+namePrefix+str(nu)+\"_\"+str(gamma),\"wb\")\n",
    "    pkl.dump(models, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(nu, gamma):\n",
    "    pickle_out = open(\"svmModels/svmmodelstandardscaled_\"+namePrefixOri+str(nu)+\"_\"+str(gamma),\"rb\")\n",
    "    models = pkl.load(pickle_out)\n",
    "    pickle_out.close()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistBloomFilters(bloomfilters, nu, gamma):\n",
    "    pickle_out = open(\"bloomfilters/bloomfilters_\"+namePrefix+str(nu)+\"_\"+str(gamma),\"wb\")\n",
    "    pkl.dump(bloomfilters, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistObservations(obs, nu, gamma):\n",
    "    pickle_out = open(\"Observations/observations_\"+namePrefix+str(nu)+\"_\"+str(gamma),\"wb\")\n",
    "    pkl.dump(obs, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistTimes(obs):\n",
    "    pickle_out = open(\"times/times_\"+namePrefix,\"wb\")\n",
    "    pkl.dump(obs, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(nu, gamma):\n",
    "    print(nu,gamma)\n",
    "    starttime = time.time()\n",
    "#     models = trainFn(nu, gamma)\n",
    "#     persistModel(models, nu, gamma)\n",
    "    models = loadModel(nu, gamma)\n",
    "    print(nu, gamma, \"inserting into bloom filters\")\n",
    "    (bloomfilters, errorTrain) = putIntoBloomFilters(models)\n",
    "    persistBloomFilters(bloomfilters, nu, gamma)\n",
    "    print(nu, gamma, \"performing tests\")\n",
    "    (fprate,\n",
    "    truePositive_c,truePositive_bf,truePositive,\n",
    "    falsePositive_c,falsePositive_bf,falsePositive,\n",
    "    trueNegative) = performTests(models, bloomfilters)\n",
    "    observations = (errorTrain, fprate,\n",
    "                    truePositive_c,truePositive_bf,truePositive,\n",
    "                    falsePositive_c,falsePositive_bf,falsePositive,\n",
    "                    trueNegative)\n",
    "    persistObservations(observations, nu, gamma)\n",
    "    endtime = time.time()\n",
    "    return (endtime-starttime, nu, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramsize = -1\n",
    "maxiter = 100\n",
    "# models = {} # storing models based on sstable ids\n",
    "# nu = 0.1\n",
    "# gamma = 1\n",
    "removeClassifier = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thres = -0.1\n",
    "# bloomfilters = {}\n",
    "capacityBloom = 30000\n",
    "errorRate = 0.1\n",
    "skipFactor = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssTableData = {}\n",
    "separator = \":\"\n",
    "namePrefix = \"6nu6gamma_ex4_e2\"\n",
    "namePrefixOri = \"6nu6gamma_ex4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120691)\n",
      "(2, 126781)\n",
      "(3, 125351)\n",
      "(4, 119538)\n",
      "(5, 126719)\n",
      "(6, 25367)\n",
      "(7, 29100)\n",
      "(8, 28898)\n",
      "(9, 30806)\n",
      "(10, 16550)\n",
      "(11, 35023)\n",
      "(12, 5815)\n",
      "(13, 17015)\n",
      "(14, 405)\n",
      "(15, 4266)\n",
      "(16, 1265)\n",
      "(17, 16967)\n",
      "(18, 1963)\n",
      "(19, 880)\n",
      "(20, 397)\n",
      "(21, 1283)\n",
      "(22, 845)\n",
      "(23, 368)\n",
      "(24, 3071)\n",
      "CPU times: user 43.9 s, sys: 2.97 s, total: 46.9 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "(ssTableData, alltemptableData) = getData()\n",
    "ssTableData, dimlist = createNgrams(ssTableData, alltemptableData)\n",
    "scalers = getScalers()\n",
    "# nus = np.logspace(-3,0,6)\n",
    "# gammas = np.logspace(-3,3,6)\n",
    "nus = np.logspace(-3,0,6)\n",
    "gammas = np.logspace(-1,3,6)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltemptableData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu = nus[3]\n",
    "# gamma = gammas[5]\n",
    "tempresult = ensemble(nu,gamma)\n",
    "print(tempresult)\n",
    "# tempmodel = loadModel(nu, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempmodel['0'][0].support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempmodel['0'][0].predict(tempmodel['0'][0].support_vectors_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(tempmodel['0'][0].score_samples(tempmodel['0'][0].support_vectors_[:20]) + tempmodel['0'][0].intercept_>-1e4,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempmodel['0'][0].score_samples(tempmodel['1'][0].support_vectors_[:20]) + tempmodel['0'][0].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempmodel['0'][0].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:00, 238.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(82.34153890609741, 0.001, 0.1), (1201.0263288021088, 0.001, 0.6309573444801934), (7345.555503845215, 0.001, 3.981071705534973), (10999.846466064453, 0.001, 25.11886431509582), (13118.432667970657, 0.001, 158.48931924611142), (13236.959196090698, 0.001, 1000.0), (149.23349809646606, 0.003981071705534973, 0.1), (1229.0328691005707, 0.003981071705534973, 0.6309573444801934), (8212.232585906982, 0.003981071705534973, 3.981071705534973), (12994.617852926254, 0.003981071705534973, 25.11886431509582), (13274.464619159698, 0.003981071705534973, 158.48931924611142), (13237.320447921753, 0.003981071705534973, 1000.0), (368.1185419559479, 0.015848931924611134, 0.1), (1273.8139629364014, 0.015848931924611134, 0.6309573444801934), (8335.32002401352, 0.015848931924611134, 3.981071705534973), (13119.387156963348, 0.015848931924611134, 25.11886431509582), (12840.421779155731, 0.015848931924611134, 158.48931924611142), (12844.247657060623, 0.015848931924611134, 1000.0), (1140.1365039348602, 0.0630957344480193, 0.1), (1652.9507529735565, 0.0630957344480193, 0.6309573444801934), (7410.530214071274, 0.0630957344480193, 3.981071705534973), (13182.455356836319, 0.0630957344480193, 25.11886431509582), (12820.741302967072, 0.0630957344480193, 158.48931924611142), (13238.356121778488, 0.0630957344480193, 1000.0), (4935.351305961609, 0.25118864315095796, 0.1), (5272.953957080841, 0.25118864315095796, 0.6309573444801934), (8762.571720838547, 0.25118864315095796, 3.981071705534973), (12610.284087181091, 0.25118864315095796, 25.11886431509582), (13224.541547060013, 0.25118864315095796, 158.48931924611142), (12836.802872180939, 0.25118864315095796, 1000.0), (13562.751742839813, 1.0, 0.1), (13146.691467046738, 1.0, 0.6309573444801934), (13206.428089857101, 1.0, 3.981071705534973), (13213.755298137665, 1.0, 25.11886431509582), (12879.970175981522, 1.0, 158.48931924611142), (13221.013412952423, 1.0, 1000.0)]\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=num_cores)(delayed(ensemble)(i,j) for i,j in tqdm(product(nus, gammas)))\n",
    "print(results)\n",
    "# for nu, gamma in product(nus, gammas):\n",
    "#     tempresult = ensemble(nu,gamma)\n",
    "#     print(tempresult)\n",
    "# tempresult = ensemble(nu,gamma)\n",
    "# print(tempresult)\n",
    "\n",
    "# models = trainFn(0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(82.34153890609741, 0.001, 0.1),\n",
       " (1201.0263288021088, 0.001, 0.6309573444801934),\n",
       " (7345.555503845215, 0.001, 3.981071705534973),\n",
       " (10999.846466064453, 0.001, 25.11886431509582),\n",
       " (13118.432667970657, 0.001, 158.48931924611142),\n",
       " (13236.959196090698, 0.001, 1000.0),\n",
       " (149.23349809646606, 0.003981071705534973, 0.1),\n",
       " (1229.0328691005707, 0.003981071705534973, 0.6309573444801934),\n",
       " (8212.232585906982, 0.003981071705534973, 3.981071705534973),\n",
       " (12994.617852926254, 0.003981071705534973, 25.11886431509582),\n",
       " (13274.464619159698, 0.003981071705534973, 158.48931924611142),\n",
       " (13237.320447921753, 0.003981071705534973, 1000.0),\n",
       " (368.1185419559479, 0.015848931924611134, 0.1),\n",
       " (1273.8139629364014, 0.015848931924611134, 0.6309573444801934),\n",
       " (8335.32002401352, 0.015848931924611134, 3.981071705534973),\n",
       " (13119.387156963348, 0.015848931924611134, 25.11886431509582),\n",
       " (12840.421779155731, 0.015848931924611134, 158.48931924611142),\n",
       " (12844.247657060623, 0.015848931924611134, 1000.0),\n",
       " (1140.1365039348602, 0.0630957344480193, 0.1),\n",
       " (1652.9507529735565, 0.0630957344480193, 0.6309573444801934),\n",
       " (7410.530214071274, 0.0630957344480193, 3.981071705534973),\n",
       " (13182.455356836319, 0.0630957344480193, 25.11886431509582),\n",
       " (12820.741302967072, 0.0630957344480193, 158.48931924611142),\n",
       " (13238.356121778488, 0.0630957344480193, 1000.0),\n",
       " (4935.351305961609, 0.25118864315095796, 0.1),\n",
       " (5272.953957080841, 0.25118864315095796, 0.6309573444801934),\n",
       " (8762.571720838547, 0.25118864315095796, 3.981071705534973),\n",
       " (12610.284087181091, 0.25118864315095796, 25.11886431509582),\n",
       " (13224.541547060013, 0.25118864315095796, 158.48931924611142),\n",
       " (12836.802872180939, 0.25118864315095796, 1000.0),\n",
       " (13562.751742839813, 1.0, 0.1),\n",
       " (13146.691467046738, 1.0, 0.6309573444801934),\n",
       " (13206.428089857101, 1.0, 3.981071705534973),\n",
       " (13213.755298137665, 1.0, 25.11886431509582),\n",
       " (12879.970175981522, 1.0, 158.48931924611142),\n",
       " (13221.013412952423, 1.0, 1000.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistTimes(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namePrefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempData = ssTableData[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(tempData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidData = tempData[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blkdata = tempData[:,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(vidData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(vidData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(vidData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(vidData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.var(vidData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.sort(vidData), bins=40)\n",
    "plt.ylabel('vid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
