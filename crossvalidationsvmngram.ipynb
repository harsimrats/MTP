{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# get_ipython().magic(u'matplotlib inline')\n",
    "from pybloom import BloomFilter\n",
    "import inspect\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "import os\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import time\n",
    "# get_ipython().magic(u'matplotlib notebook')\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn import mixture\n",
    "import math\n",
    "\n",
    "def readFileByLines(filename):\n",
    "    f = open(filename, 'r')\n",
    "    lst = f.readlines()\n",
    "    f.close()\n",
    "#     print(lst)\n",
    "#     lst = map(str.rstrip, lst)\n",
    "    return lst\n",
    "\n",
    "def parseVdisk(lst):\n",
    "    lst = [s.split(':') for s in lst]\n",
    "#     vid = []\n",
    "#     blc = [] \n",
    "    mat = []\n",
    "    for ele in lst:\n",
    "#         vid.append(int(ele[1]))\n",
    "#         blc.append(int(ele[2], 16))\n",
    "        mat.append([float(int(ele[1]))/1e0,float(int(ele[2], 16))/1e0])\n",
    "#     print(vid, blc)\n",
    "#     return (vid, blc)\n",
    "    return mat\n",
    "\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def persistModel(models, nu, gamma):\n",
    "    pickle_out = open(\"svmModels/svmmodelstandardscaled_\"+namePrefix+str(nu)+\"_\"+str(gamma),\"wb\")\n",
    "    pkl.dump(models, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def loadModel(nu, gamma):\n",
    "    pickle_out = open(\"svmModels/svmmodelstandardscaled_\"+namePrefixOri+str(nu)+\"_\"+str(gamma),\"rb\")\n",
    "    models = pkl.load(pickle_out)\n",
    "    pickle_out.close()\n",
    "    return models\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "def persistBloomFilters(bloomfilters, nu, gamma):\n",
    "    pickle_out = open(\"bloomfilters/bloomfilters_\"+namePrefix+str(nu)+\"_\"+str(gamma),\"wb\")\n",
    "    pkl.dump(bloomfilters, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def persistObservations(obs, nu, gamma):\n",
    "    pickle_out = open(\"Observations/observations_\"+namePrefix+str(nu)+\"_\"+str(gamma),\"wb\")\n",
    "    pkl.dump(obs, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "def persistTimes(obs):\n",
    "    pickle_out = open(\"times/times_\"+namePrefix,\"wb\")\n",
    "    pkl.dump(obs, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "def getData():\n",
    "    foldername = \"metadata_maps/vdisk/*.db\"\n",
    "    files = sorted(glob.glob(foldername))\n",
    "    ctr=0\n",
    "    alltemptableData = []\n",
    "    for fle in files:\n",
    "        thisline = readFileByLines(fle)\n",
    "    #     if(len(thisline)>1000):\n",
    "    #         continue\n",
    "        mat = parseVdisk(thisline)\n",
    "        ssTableData[ctr] = np.array(mat).reshape(-1,2)\n",
    "        ctr+=1\n",
    "        alltemptableData+=mat\n",
    "        print(ctr,len(thisline))\n",
    "    # print(lines)\n",
    "    alltemptableData = np.array(alltemptableData).reshape(-1,2)\n",
    "    return (ssTableData, alltemptableData)\n",
    "\n",
    "def getScalers(whichParamKCross):\n",
    "    scalers = {}\n",
    "    for i in range(0,len(trainData)):\n",
    "        thistableData = trainData[i][whichParamKCross]\n",
    "        scaler = preprocessing.StandardScaler().fit(thistableData)\n",
    "        scalers[i] = scaler\n",
    "    return scalers\n",
    "\n",
    "def ngramMaxDimKnown(Xd, gramsize, maxlen):\n",
    "    X = map(str, Xd)\n",
    "    numele = len(X)\n",
    "    reqdim = maxlen - gramsize +1\n",
    "    \n",
    "    Y = []\n",
    "    for i in X:\n",
    "        tempy = []\n",
    "        paddedi = i + \"0\"*(maxlen-len(i))\n",
    "        for j in range(0,len(paddedi)-gramsize+1):\n",
    "            tempy.append(paddedi[j:j+gramsize])\n",
    "        if len(tempy) == 0:\n",
    "            tempy = [paddedi]\n",
    "        templeny = len(tempy)\n",
    "        \n",
    "        Y.append(tempy)\n",
    "    return Y\n",
    "\n",
    "def createNgramsPerSStable(thisssTableData, alltemptableData, mingram, maxgram):\n",
    "#     mingram = 6\n",
    "#     maxgram = 6\n",
    "    initialDimension = alltemptableData.shape[1]\n",
    "    \n",
    "    extrapolatedData = thisssTableData\n",
    "    findimlist = []\n",
    "    for realFeature in range(initialDimension):\n",
    "    #     not taking care of negative features\n",
    "        thisFeatureData = thisssTableData[:,realFeature]\n",
    "        maxlen = len(str(np.max(alltemptableData[:,realFeature])))\n",
    "        dimlist = []\n",
    "        for gramsize in range(mingram, min(maxgram,maxlen)+1):\n",
    "#             print(thisFeatureData[0], gramsize, maxlen)\n",
    "#             print(gramsize)\n",
    "            thisFeatureDataOfGramSize = np.array(ngramMaxDimKnown(thisFeatureData, gramsize, maxlen),dtype=np.float)\n",
    "#             print(thisFeatureDataOfGramSize[0])\n",
    "#             print(thisFeatureDataOfGramSize.shape)\n",
    "            reqdimForLater = thisFeatureDataOfGramSize.shape[1]\n",
    "#             print(reqdimForLater)\n",
    "            dimlist.append(reqdimForLater)\n",
    "            extrapolatedData = np.append(extrapolatedData, thisFeatureDataOfGramSize, axis=1)\n",
    "        findimlist += dimlist\n",
    "    return (extrapolatedData, findimlist)\n",
    "def createNgrams(ssTableData, alltemptableData, mingram, maxgram):\n",
    "    ngramData = {}\n",
    "    dimlists = []\n",
    "    for i in range(len(ssTableData)):\n",
    "        (bigData, dimlist)=createNgramsPerSStable(ssTableData[i], alltemptableData, mingram, maxgram)\n",
    "        ngramData[i] = bigData\n",
    "        dimlists.append(dimlist)\n",
    "    return (ngramData, dimlists)\n",
    "\n",
    "def trainIndiSvm(nplst1, sstableID, nu, gamma, models):\n",
    "    print(\"passed mean was \",np.mean(nplst1, axis=0))\n",
    "    print(\"passed sigma was \",np.var(nplst1, axis=0))\n",
    "    clf = svm.OneClassSVM(nu=nu, kernel=\"rbf\", gamma=gamma)\n",
    "    clf.fit(nplst1)\n",
    "    reqdim = len(nplst1[0])\n",
    "#     print(\"reqdim is \",reqdim)\n",
    "    models[str(sstableID)] = (clf, reqdim)\n",
    "    print('training done with sstableid - ', sstableID)\n",
    "    return models\n",
    "\n",
    "def trainFn(whichParamKCross, nu, gamma):\n",
    "    # train the model on generated data\n",
    "    models = {}\n",
    "    for i in range(0,len(trainData)):\n",
    "        starttime = time.time()\n",
    "        thistableData = trainData[i][whichParamKCross]\n",
    "        models = trainIndiSvm(scalers[i].transform(thistableData),i, nu, gamma, models)\n",
    "        endtime = time.time()\n",
    "        print(str(nu),str(gamma),\"time taken \", (endtime-starttime))\n",
    "    return models\n",
    "def mypredSvm(X, clf):\n",
    "#     scores = clf.predict(X)\n",
    "#     return scores\n",
    "    return np.where(clf.score_samples(X)+clf.intercept_ > -1e-3, 1, -1)\n",
    "\n",
    "def testIndiSvm(keyPredg, sstableID, models):\n",
    "#     if(keyPredstr == ''):\n",
    "#         print('returning cause string is empty')\n",
    "#         return 0\n",
    "#     if(not isCharacterAscii(keyPredstr)):\n",
    "#         print('returning cause not numric')\n",
    "#         return 0\n",
    "#     keyPred = [str(keyPredstr)]\n",
    "    if str(sstableID) in models:\n",
    "        # sizeofmodels()\n",
    "        clf, reqdim= models[str(sstableID)]\n",
    "#         keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "#         keyPredS = preprocess_test([keyPredg], min_max_scaler)\n",
    "        prediction = mypredSvm([keyPredg], clf)\n",
    "        return prediction[0]\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "def testIndiSvm2(keyPredg, sstableID, models):\n",
    "#     if(keyPredstr == ''):\n",
    "#         print('returning cause string is empty')\n",
    "#         return 0\n",
    "#     if(not isCharacterAscii(keyPredstr)):\n",
    "#         print('returning cause not numric')\n",
    "#         return 0\n",
    "#     keyPred = [str(keyPredstr)]\n",
    "    if str(sstableID) in models:\n",
    "        # sizeofmodels()\n",
    "        clf, reqdim= models[str(sstableID)]\n",
    "#         keyPredg = ngramEnforce(keyPred, gramsize, reqdim)\n",
    "#         keyPredS = preprocess_test([keyPredg], min_max_scaler)\n",
    "        prediction = mypredSvm(keyPredg, clf)\n",
    "        return prediction\n",
    "    else:\n",
    "        print(str(sstableID), ' - sstableid not in models')\n",
    "        return 0\n",
    "\n",
    "def putIntoBloomFilters(whichParamKCross,models):\n",
    "    bloomfilters = {}\n",
    "    errorsTrain = {}\n",
    "    validationFalseNegative = {}\n",
    "    for i in range(0,len(ssTableData)):\n",
    "        print(\"bf creating for \",i)\n",
    "        thistableData = ssTableData[i]\n",
    "        thistableDataTranspose0 = thistableData.transpose()[0]\n",
    "        if removeClassifier:\n",
    "            newCapacity = max(len(thistableData),1)\n",
    "            print(\"newCapacity \",newCapacity)\n",
    "            f = BloomFilter(capacity=newCapacity, error_rate=errorRate)\n",
    "            for j in range(0,len(thistableData)):\n",
    "                f.add(separator.join(map(str,thistableData[j])))\n",
    "            bloomfilters[i] = f\n",
    "        else:\n",
    "            falseNegativeAns = testIndiSvm2(scalers[i].transform(thistableData), i, models)\n",
    "        #     print(falseNegativeAns)\n",
    "            numFalseNeg = falseNegativeAns.tolist().count(-1)\n",
    "        #     newCapacity = int(capacityBloom*1.0*numFalseNeg/len(thistableData))\n",
    "            newCapacity = max(numFalseNeg,1)\n",
    "            print(\"newCapacity \",newCapacity)\n",
    "            f = BloomFilter(capacity=newCapacity, error_rate=errorRate)\n",
    "            for j in range(0,len(thistableData)):\n",
    "                if(falseNegativeAns[j]==-1 or removeClassifier):\n",
    "        #             print(\"adding \", thistableDataTranspose0[j])\n",
    "                    f.add(separator.join(map(str,thistableData[j])))\n",
    "            bloomfilters[i] = f\n",
    "            falseNegaiveValidation = testIndiSvm2(scalers[i].transform(validationData[i][whichParamKCross]), i, models)\n",
    "            numFalseNegValidation = falseNegaiveValidation.tolist().count(-1)\n",
    "            validationFalseNegative[i] = numFalseNegValidation\n",
    "            errorsTrain[i] = numFalseNeg\n",
    "    return (bloomfilters,errorsTrain, validationFalseNegative)\n",
    "\n",
    "def performTests(models, bloomfilters):\n",
    "    # create test data\n",
    "    # For now test data is all data\n",
    "    # calculate false positives for test data\n",
    "    truePositive_c=0\n",
    "    truePositive_bf=0\n",
    "    truePositive=0\n",
    "    falsePositive_c=0\n",
    "    falsePositive_bf=0\n",
    "    falsePositive=0\n",
    "    trueNegative=0\n",
    "    for i in range(0, len(ssTableData)):\n",
    "        print(\"on sstable number \", i)\n",
    "        thistableData = ssTableData[i]\n",
    "        thistableDataTranspose0 = thistableData.transpose()[0]\n",
    "        for elemind in range(0,len(thistableData),skipFactor):\n",
    "            elem = thistableData[elemind]\n",
    "            for j in range(0,len(ssTableData)):\n",
    "                if removeClassifier:\n",
    "                    cAnswer = False\n",
    "                else:\n",
    "                    cAnswer = (testIndiSvm(scalers[j].transform([elem])[0],j, models)==1)\n",
    "    #             print(cAnswer)\n",
    "                if not cAnswer:\n",
    "                    bfAnswer = separator.join(map(str,elem)) in bloomfilters[j]\n",
    "                    finAnswer = bfAnswer\n",
    "                else:\n",
    "                    bfAnswer = None\n",
    "                    finAnswer = cAnswer\n",
    "                if finAnswer:\n",
    "                    if(i==j):\n",
    "                        #True answer true positive\n",
    "                        #break because you found answer\n",
    "                        truePositive+=1\n",
    "                        if bfAnswer is None:\n",
    "                            truePositive_c+=1\n",
    "                        else:\n",
    "                            truePositive_bf+=1\n",
    "                        break\n",
    "                    else:\n",
    "                        #False answer false positive\n",
    "                        falsePositive+=1\n",
    "                        if bfAnswer is None:\n",
    "                            falsePositive_c+=1\n",
    "                        else:\n",
    "                            falsePositive_bf+=1\n",
    "                else:\n",
    "                    if(i==j):\n",
    "                        raise ValueEroor(\"not possible\")\n",
    "                    else:\n",
    "                        #True answer true negative\n",
    "                        trueNegative+=1\n",
    "    fprate = falsePositive*1.0/(falsePositive+trueNegative)\n",
    "    return (fprate,\n",
    "            truePositive_c,truePositive_bf,truePositive,\n",
    "            falsePositive_c,falsePositive_bf,falsePositive,\n",
    "            trueNegative)\n",
    "\n",
    "def ensemble(whichParamKCross, nu, gamma):\n",
    "    print(nu,gamma)\n",
    "    starttime = time.time()\n",
    "    models = trainFn(whichParamKCross, nu, gamma)\n",
    "    persistModel(models, nu, gamma)\n",
    "    # models = loadModel(nu, gamma)\n",
    "    print(nu, gamma, \"inserting into bloom filters\")\n",
    "    (bloomfilters, errorTrain, validationFalseNeg) = putIntoBloomFilters(whichParamKCross,models)\n",
    "    persistBloomFilters(bloomfilters, nu, gamma)\n",
    "    print(nu, gamma, \"performing tests\")\n",
    "    (fprate,\n",
    "    truePositive_c,truePositive_bf,truePositive,\n",
    "    falsePositive_c,falsePositive_bf,falsePositive,\n",
    "    trueNegative) = performTests(models, bloomfilters)\n",
    "    observations = (errorTrain, fprate,\n",
    "                    truePositive_c,truePositive_bf,truePositive,\n",
    "                    falsePositive_c,falsePositive_bf,falsePositive,\n",
    "                    trueNegative,validationFalseNeg)\n",
    "    persistObservations(observations, nu, gamma)\n",
    "    endtime = time.time()\n",
    "    return (endtime-starttime, nu, gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramsize = -1\n",
    "maxiter = 100\n",
    "# models = {} # storing models based on sstable ids\n",
    "# nu = 0.1\n",
    "# gamma = 1\n",
    "removeClassifier = False\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "# thres = -0.1\n",
    "# bloomfilters = {}\n",
    "capacityBloom = 30000\n",
    "errorRate = 0.1\n",
    "skipFactor = 50\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "ssTableData = {}\n",
    "validationData = {}\n",
    "trainData = {}\n",
    "separator = \":\"\n",
    "namePrefix = \"crossvalidation_e3\"\n",
    "numPrefixBackup = namePrefix\n",
    "# namePrefixOri = \"6nu6gamma_ex4\"\n",
    "namePrefixOri = \"crossvalidation_e3\"\n",
    "\n",
    "paramKCross = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120691)\n",
      "(2, 126781)\n",
      "(3, 125351)\n",
      "(4, 119538)\n",
      "(5, 126719)\n",
      "(6, 25367)\n",
      "(7, 29100)\n",
      "(8, 28898)\n",
      "(9, 30806)\n",
      "(10, 16550)\n",
      "(11, 35023)\n",
      "(12, 5815)\n",
      "(13, 17015)\n",
      "(14, 405)\n",
      "(15, 4266)\n",
      "(16, 1265)\n",
      "(17, 16967)\n",
      "(18, 1963)\n",
      "(19, 880)\n",
      "(20, 397)\n",
      "(21, 1283)\n",
      "(22, 845)\n",
      "(23, 368)\n",
      "(24, 3071)\n"
     ]
    }
   ],
   "source": [
    "(ssTableData, alltemptableData) = getData()\n",
    "ssTableData, dimlist = createNgrams(ssTableData, alltemptableData, 4, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssTableDataOriginalDimension = ssTableData[0].shape[1]\n",
    "for i in range(len(ssTableData)):\n",
    "    np.random.shuffle(ssTableData[i])\n",
    "    validationData[i] = np.array_split(ssTableData[i], paramKCross)\n",
    "    trainData[i] = [np.concatenate(validationData[i][:j]+validationData[i][(j+1):]) for j in range(paramKCross)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 149.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for whichParamKCross in range(paramKCross):\n",
    "    namePrefix = numPrefixBackup + \"_\" + str(whichParamKCross)\n",
    "    scalers = getScalers(whichParamKCross)\n",
    "    nus = np.logspace(-3,0,6)[2:5]\n",
    "    gammas = np.logspace(-1,3,6)[2:]\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    results = Parallel(n_jobs=num_cores)(delayed(ensemble)(whichParamKCross,i,j) for i,j in tqdm(product(nus, gammas)))\n",
    "    persistTimes(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
